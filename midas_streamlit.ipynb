{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime as dt\n",
    "import os \n",
    "import json\n",
    "import requests\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from tvDatafeed import TvDatafeed, Interval\n",
    "tv = TvDatafeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fintables Sektörler ve Şirketler Güncelleniyor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fintables Şirketler: 100%|██████████| 44/44 [00:03<00:00, 13.29it/s]\n",
      "100%|██████████| 11/11 [00:06<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_sector_wide(data, sector_name):\n",
    "    rename_dict = {\n",
    "        \"Sektör Ortalamaları\": \"Metrics\",\n",
    "        \"F/K\": \"fk\",\n",
    "        \"PD/DD\": \"pd_dd\",\n",
    "        \"FD/FAVÖK\": \"fd_favok\"\n",
    "    }\n",
    "    \n",
    "    data = data.rename(columns=rename_dict)\n",
    "\n",
    "    \n",
    "    new_columns = {\n",
    "        \"BIST 100\": \"bist100\",\n",
    "        \"Aritmetik Ortalama\": \"ao\",\n",
    "        \"Ağırlıklı Ortalama\": \"wo\",\n",
    "        \"Medyan\": \"median\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    wide_df = pd.DataFrame()\n",
    "    wide_df['sector_name'] = [sector_name]\n",
    "\n",
    "    for metric, prefix in new_columns.items():\n",
    "        for column in ['fk', 'pd_dd', 'fd_favok']:\n",
    "            col_name = f\"{prefix}_{column}\"\n",
    "            if sector_name == 'bankacilik' and column == 'fd_favok':\n",
    "                wide_df[col_name] = np.nan\n",
    "            else:\n",
    "                wide_df[col_name] = data[data['Metrics'] == metric][column].values\n",
    "\n",
    "    return wide_df\n",
    "\n",
    "# Function to convert 'Piyasa Değeri' to numerical value\n",
    "def convert_piyasa_degeri(value):\n",
    "    value = value.replace('₺', '').strip()\n",
    "    if 'mr' in value:\n",
    "        value = float(value.replace('mr', '')) * 1e3  # convert to billion\n",
    "    elif 'mn' in value:\n",
    "        value = float(value.replace('mn', ''))  # convert to million\n",
    "    return value\n",
    "\n",
    "def get_sector(sector_name):\n",
    "\n",
    "    headers = {\n",
    "        'authority': 'fintables.com',\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'accept-language': 'en-US,en;q=0.9,tr;q=0.8,tr-TR;q=0.7',\n",
    "        'cache-control': 'no-cache',\n",
    "        'cookie': '_gid=GA1.2.50961081.1690710140; _gcl_au=1.1.518997462.1690710149; auth-token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoyMTIyNzEwMTk3LCJpYXQiOjE2OTA3MTAxOTcsImp0aSI6IjQ2NGI0YTIxYjY3ZjQ3ZDY4MmEwYjg5NWE3ZjlkMWE4IiwidXNlcl9pZCI6MTEyNzMzfQ.Bh3945i5RjYHblFOyoN_e9oqVmQcOUukFo8GqXp5wtg; _gat_UA-72451211-3=1; _ga=GA1.2.1134893438.1690710140; _ga_22JQCWWZZJ=GS1.1.1690710149.1.1.1690711335.20.0.0',\n",
    "        'dnt': '1',\n",
    "        'pragma': 'no-cache',\n",
    "        'sec-ch-ua': '\"Not.A/Brand\";v=\"8\", \"Chromium\";v=\"114\", \"Google Chrome\";v=\"114\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"macOS\"',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'sec-fetch-user': '?1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(f'https://fintables.com/sektorler/{sector_name}', headers=headers)\n",
    "\n",
    "    # The content of the response\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    sektor_ozet = soup.find_all('table', class_=\"min-w-full\")[0]\n",
    "    sektor_ozet2 = str(sektor_ozet).replace(\".\",\"\").replace(',', '.')\n",
    "    sektor_ozet_df = pd.read_html(str(sektor_ozet2))[0]\n",
    "    sektor_ozet_wide = convert_sector_wide(sektor_ozet_df, sector_name)\n",
    "    \n",
    "    my_table = soup.find_all('table', class_=\"min-w-full\")[1]\n",
    "    my_table2 = str(my_table).replace(\".\",\"\").replace(',', '.')\n",
    "    df = pd.read_html(str(my_table2))[0]\n",
    "    \n",
    "    df['Piyasa Değeri'] = df['Piyasa Değeri'].apply(convert_piyasa_degeri)\n",
    "    #df['Piyasa Değeri'] = df['Piyasa Değeri'].astype(int)\n",
    "    df[\"sector\"] = sector_name\n",
    "\n",
    "    return sektor_ozet_wide, df\n",
    "\n",
    "def get_sector_multiple(sector_names):\n",
    "    ozet_list = []\n",
    "    sirket_list = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for sektor_ozet,tum_sirketler in tqdm(executor.map(get_sector, sector_names), total=len(sector_names), desc=\"Fintables Şirketler\"):\n",
    "            try:\n",
    "                sirket_list.append(tum_sirketler)\n",
    "                ozet_list.append(sektor_ozet)\n",
    "            except Exception as e:\n",
    "                print(\"Error: \", e)\n",
    "    sirket_df = pd.concat(sirket_list, axis=0, ignore_index=True)\n",
    "    ozet_df = pd.concat(ozet_list, axis=0, ignore_index=True)\n",
    "\n",
    "    sirket_df['Şirket Kodu'] = sirket_df['Şirket Kodu'].str[:-7]\n",
    "    # sirket_df['Piyasa Değeri'] = sirket_df['Piyasa Değeri'].astype(float)\n",
    "\n",
    "    sirket_df.columns = ['sirket_kodu', 'piyasa_degeri', 'fk', 'pd_dd', 'fd_favok', 'sector']\n",
    "    return ozet_df, sirket_df\n",
    "\n",
    "sector_names = json.load(open('sector_names.json',encoding=\"utf-8\"))\n",
    "\n",
    "print(\"Fintables Sektörler ve Şirketler Güncelleniyor\")\n",
    "ozet_df, sirket_df = get_sector_multiple(sector_names)\n",
    "\n",
    "all_tickers = sirket_df['sirket_kodu'].unique()\n",
    "all_tickers = list(all_tickers[:10])\n",
    "all_tickers.append('XU100')\n",
    "data_list = []\n",
    "\n",
    "def fetch_data(ticker):\n",
    "    data = tv.get_hist(symbol=ticker, exchange='BIST', interval=Interval.in_daily, n_bars=200)\n",
    "    return data\n",
    "\n",
    "# Use a ThreadPoolExecutor to fetch data in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Wrap the executor and the ticker list with tqdm for a progress bar\n",
    "    data_list = list(tqdm(executor.map(fetch_data, all_tickers), total=len(all_tickers)))\n",
    "\n",
    "\n",
    "data = pd.concat(data_list).reset_index()\n",
    "data[\"symbol\"] = data[\"symbol\"].str[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_no_sell(grouped):\n",
    "    grouped.insert(2,\"d_q_s\", 0)\n",
    "    grouped.insert(3,\"d_q_c\",grouped[\"d_q_b\"] - grouped[\"d_q_s\"])\n",
    "    grouped.insert(5,\"d_a_s\",0)\n",
    "    grouped[\"d_p_s\"] = 0\n",
    "\n",
    "    grouped = grouped.fillna(0)\n",
    "    grouped[\"h_q\"] = grouped[\"d_q_c\"].cumsum()\n",
    "    \n",
    "\n",
    "    grouped[\"a_a_b\"] = grouped[\"d_a_b\"].cumsum() \n",
    "    grouped[\"a_a_s\"] = grouped[\"d_a_s\"].cumsum() \n",
    "\n",
    "    grouped[\"a_p_b\"] = grouped[\"a_a_b\"] / grouped[\"h_q\"]\n",
    "\n",
    "    grouped[\"a_p_b\"] = grouped[\"a_p_b\"].apply(lambda x: round(x,2))\n",
    "    grouped[\"d_r_p\"] = 0\n",
    "    grouped[\"a_r_p\"] = 0\n",
    "    grouped.insert(9,\"h_a\",grouped[\"a_p_b\"] * grouped[\"h_q\"])\n",
    "    grouped[\"h_a\"] = grouped[\"h_a\"].apply(lambda x: round(x,2))\n",
    "    return grouped\n",
    "\n",
    "def p_buy_and_sell(grouped):\n",
    "    grouped = grouped.fillna(0)\n",
    "    grouped.insert(3,\"d_q_c\",grouped[\"d_q_b\"] - grouped[\"d_q_s\"])\n",
    "    grouped[\"h_q\"] = grouped[\"d_q_c\"].cumsum()\n",
    "    \n",
    "\n",
    "    grouped[\"a_a_b\"] = grouped[\"d_a_b\"].cumsum() \n",
    "    grouped[\"a_a_s\"] = grouped[\"d_a_s\"].cumsum() \n",
    "\n",
    "    grouped.loc[0,\"a_p_b\"] = grouped.loc[0,\"a_a_b\"] / grouped.loc[0,\"h_q\"]\n",
    "\n",
    "    for i, val in grouped.iterrows():\n",
    "        #Eğer tüm hisseler o gün satıldıysa, bir sonraki gündeki ortalama fiyat sadece yeni alınan hisselerin ortalaması olur.\n",
    "        #Eğer tüm hisseler o gün satıldıysa, ve o gün alım olmadıysa, ortalama önceki güne eşit olur.\n",
    "        if val[\"h_q\"] == 0:\n",
    "            if val[\"d_q_b\"] == 0:\n",
    "                grouped.loc[i,\"a_p_b\"] = grouped.loc[i-1,\"a_p_b\"]\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            #Eğer alış olmadıysa, eldeki maliyet değişmez.\n",
    "            if val[\"d_q_b\"] == 0:\n",
    "                grouped.loc[i,\"a_p_b\"] = grouped.loc[i-1,\"a_p_b\"]\n",
    "            else:\n",
    "                grouped.loc[i,\"a_p_b\"] = (grouped.loc[:i,\"d_a_b\"].sum() - grouped.loc[:i,\"d_a_s\"].sum()) / grouped.loc[i,\"h_q\"]\n",
    "            # grouped.loc[i,\"a_p_b\"] = val[\"a_a_b\"] / val[\"h_q\"]\n",
    "        if 0 in grouped.loc[:i,\"h_q\"].values:\n",
    "            \n",
    "            last_zero_index = grouped.loc[:i,\"h_q\"].tolist().index(0)\n",
    "            if val[\"d_q_b\"] != 0:\n",
    "                grouped.loc[i,\"a_p_b\"] = sum_product = grouped.loc[last_zero_index:i, \n",
    "                                        \"d_p_b\"].mul(grouped.loc[last_zero_index:i, \"d_q_b\"]).sum() / grouped.loc[last_zero_index:i,\"d_q_b\"].sum()\n",
    "        if val[\"d_q_s\"] > 0:\n",
    "            last_average_buy = grouped.loc[:i].query(\"d_p_b != 0\")[\"d_p_b\"].iloc[-1]\n",
    "            grouped.loc[i,\"d_r_p\"] = (val[\"d_p_s\"] - last_average_buy) * val[\"d_q_s\"]\n",
    "        else:\n",
    "            grouped.loc[i,\"d_r_p\"] = 0\n",
    "        grouped.loc[i,\"a_r_p\"] = grouped.loc[:i,\"d_r_p\"].sum()\n",
    "    \n",
    "    grouped[\"a_p_b\"] = grouped[\"a_p_b\"].apply(lambda x: round(x,2))\n",
    "        \n",
    "    grouped.insert(9,\"h_a\",grouped[\"a_p_b\"] * grouped[\"h_q\"])\n",
    "    grouped[\"h_a\"] = grouped[\"h_a\"].apply(lambda x: round(x,2))\n",
    "    return grouped\n",
    "\n",
    "def port_func1(ticker,df):\n",
    "    data = df.query(\"ticker == @ticker\")\n",
    "    data[\"date\"] = data[\"date\"].apply(lambda x: x.normalize())\n",
    "\n",
    "    df1 = data.groupby([\"date\", \"buy_sell\"]).agg({\n",
    "        \"quantity\": \"sum\",\n",
    "        \"trans_amount\": \"sum\",\n",
    "        \"price\": lambda x: (x * data.loc[x.index, \"quantity\"]).sum() / df.loc[x.index, \"quantity\"].sum()\n",
    "    }).unstack()\n",
    "\n",
    "    df1.columns = [\"_\".join(col).strip() for col in df1.columns.values]\n",
    "    df1 = df1.rename(columns={\n",
    "        \"quantity_Alış\": \"d_q_b\",\n",
    "        \"quantity_Satış\": \"d_q_s\",\n",
    "        \"trans_amount_Alış\": \"d_a_b\",\n",
    "        \"trans_amount_Satış\": \"d_a_s\",\n",
    "        \"price_Alış\": \"d_p_b\",\n",
    "        \"price_Satış\": \"d_p_s\"\n",
    "    }).reset_index()\n",
    "\n",
    "    ####Situation stock never sold:\n",
    "    if \"d_q_s\" not in df1.columns:\n",
    "        df2 = p_no_sell(df1)\n",
    "    else:\n",
    "        df2 = p_buy_and_sell(df1)\n",
    "    return ticker, df2\n",
    "\n",
    "    ticker, df3 = port_func1(ticker,df)\n",
    "\n",
    "def port_func2(ticker,df3):\n",
    "        min_date = df3[\"date\"].min()\n",
    "        if df3.loc[len(df3)-1,\"h_q\"] != 0:\n",
    "            max_date = dt.today()\n",
    "        else:\n",
    "            max_date = df3[\"date\"].max()\n",
    "        df4 = pd.DataFrame({'date': pd.date_range(start=min_date, end=max_date, freq='B').normalize()})\n",
    "        df4 = df4.merge(df3, on='date', how='left')\n",
    "        df4 = df4.fillna({\n",
    "                'd_q_b': 0,\n",
    "                'd_q_s': 0,\n",
    "                'd_a_b': 0,\n",
    "                'd_a_s': 0,\n",
    "                'd_p_b': 0,\n",
    "                'd_p_s': 0,\n",
    "                'd_q_c': 0,\n",
    "                \"d_r_p\": 0,\n",
    "            })\n",
    "        \n",
    "        df4 = df4.merge(tvdata.query(\"ticker == @ticker\")[[\"date\",\"open\",\"close\"]], on=[\"date\"],how=\"left\")\n",
    "        f_fill_col = [\"h_q\", \"a_a_b\",\"a_a_s\", \"a_p_b\", \"a_r_p\",\"close\",\"open\"] \n",
    "        #min, max, vol_ö\n",
    "        df4[f_fill_col] = df4[f_fill_col].ffill()\n",
    "        \n",
    "        df4 = df4.query(\"d_q_b + d_q_s + h_q > 0\")\n",
    "        # df4 = df4.fillna(0)\n",
    "        df4[\"h_a\"] = df4[\"h_q\"] * df4[\"a_p_b\"]\n",
    "        df4['t_v'] = df4['h_q'] * df4['close']\n",
    "        \n",
    "        df4['a_ur_p'] = df4['t_v'] - df4['h_a']\n",
    "        df4['a_ur_p'] = np.where(df4['h_q'] == 0, 0, df4['a_ur_p'])\n",
    "        df4[\"d_ur_p\"] = (df4[\"close\"] - df4[\"open\"]) * df4[\"h_q\"]\n",
    "        df4[\"d_p\"] = df4[\"d_ur_p\"] + df4[\"d_r_p\"]\n",
    "        df4[\"a_p\"] = df4[\"a_ur_p\"] + df4[\"a_r_p\"]\n",
    "        df4[\"d_%\"] = (round(df4[\"close\"] / df4[\"open\"],3) - 1) * 100\n",
    "        df4[\"a_%\"] = (round(df4[\"close\"] / df4[\"a_p_b\"],3) - 1) * 100\n",
    "        df4.reset_index(drop=True, inplace=True)\n",
    "        df4[\"d_p_b\"] = df4[\"d_p_b\"].apply(lambda x: round(x,2))\n",
    "        df4[\"open\"] = df4[\"open\"].apply(lambda x: round(x,2))\n",
    "        df4.insert(1, 'ticker', ticker)\n",
    "        return df4    \n",
    "    \n",
    "def portfoy(ticker):\n",
    "    ticker, df3 = port_func1(ticker,df)\n",
    "    df4 = port_func2(ticker,df3)\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"midas_df.parquet\")\n",
    "cum_inv_df = pd.read_parquet(\"midas_cum_inv_df.parquet\")\n",
    "tvdata = pd.read_parquet(\"output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-07 09:00:00</td>\n",
       "      <td>BAKAB</td>\n",
       "      <td>59.799999</td>\n",
       "      <td>59.799999</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>59.099998</td>\n",
       "      <td>2.021590e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-08 09:00:00</td>\n",
       "      <td>BAKAB</td>\n",
       "      <td>59.099998</td>\n",
       "      <td>59.299999</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>58.349998</td>\n",
       "      <td>1.386870e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-09 09:00:00</td>\n",
       "      <td>BAKAB</td>\n",
       "      <td>58.549999</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>57.849998</td>\n",
       "      <td>58.700001</td>\n",
       "      <td>1.587760e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-12 09:00:00</td>\n",
       "      <td>BAKAB</td>\n",
       "      <td>58.750000</td>\n",
       "      <td>60.849998</td>\n",
       "      <td>58.049999</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>3.051580e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-13 09:00:00</td>\n",
       "      <td>BAKAB</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>60.700001</td>\n",
       "      <td>58.599998</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>2.100950e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100062</th>\n",
       "      <td>2023-09-22 09:00:00</td>\n",
       "      <td>XU100</td>\n",
       "      <td>8035.049800</td>\n",
       "      <td>8094.029800</td>\n",
       "      <td>7981.230000</td>\n",
       "      <td>8039.180200</td>\n",
       "      <td>4.187311e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100063</th>\n",
       "      <td>2023-09-25 09:00:00</td>\n",
       "      <td>XU100</td>\n",
       "      <td>8105.359900</td>\n",
       "      <td>8311.160200</td>\n",
       "      <td>8096.950200</td>\n",
       "      <td>8304.830100</td>\n",
       "      <td>4.864111e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100064</th>\n",
       "      <td>2023-09-26 09:00:00</td>\n",
       "      <td>XU100</td>\n",
       "      <td>8368.509800</td>\n",
       "      <td>8389.679700</td>\n",
       "      <td>8240.830100</td>\n",
       "      <td>8242.259800</td>\n",
       "      <td>5.966519e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100065</th>\n",
       "      <td>2023-09-27 09:00:00</td>\n",
       "      <td>XU100</td>\n",
       "      <td>8275.139600</td>\n",
       "      <td>8298.650400</td>\n",
       "      <td>8170.890100</td>\n",
       "      <td>8213.759800</td>\n",
       "      <td>4.426915e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100066</th>\n",
       "      <td>2023-09-28 09:00:00</td>\n",
       "      <td>XU100</td>\n",
       "      <td>8235.790000</td>\n",
       "      <td>8288.480500</td>\n",
       "      <td>8187.960000</td>\n",
       "      <td>8218.740200</td>\n",
       "      <td>4.110880e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100067 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime symbol         open         high          low   \n",
       "0      2022-12-07 09:00:00  BAKAB    59.799999    59.799999    56.000000  \\\n",
       "1      2022-12-08 09:00:00  BAKAB    59.099998    59.299999    57.000000   \n",
       "2      2022-12-09 09:00:00  BAKAB    58.549999    59.500000    57.849998   \n",
       "3      2022-12-12 09:00:00  BAKAB    58.750000    60.849998    58.049999   \n",
       "4      2022-12-13 09:00:00  BAKAB    60.500000    60.700001    58.599998   \n",
       "...                    ...    ...          ...          ...          ...   \n",
       "100062 2023-09-22 09:00:00  XU100  8035.049800  8094.029800  7981.230000   \n",
       "100063 2023-09-25 09:00:00  XU100  8105.359900  8311.160200  8096.950200   \n",
       "100064 2023-09-26 09:00:00  XU100  8368.509800  8389.679700  8240.830100   \n",
       "100065 2023-09-27 09:00:00  XU100  8275.139600  8298.650400  8170.890100   \n",
       "100066 2023-09-28 09:00:00  XU100  8235.790000  8288.480500  8187.960000   \n",
       "\n",
       "              close        volume  \n",
       "0         59.099998  2.021590e+05  \n",
       "1         58.349998  1.386870e+05  \n",
       "2         58.700001  1.587760e+05  \n",
       "3         60.500000  3.051580e+05  \n",
       "4         59.500000  2.100950e+05  \n",
       "...             ...           ...  \n",
       "100062  8039.180200  4.187311e+09  \n",
       "100063  8304.830100  4.864111e+09  \n",
       "100064  8242.259800  5.966519e+09  \n",
       "100065  8213.759800  4.426915e+09  \n",
       "100066  8218.740200  4.110880e+09  \n",
       "\n",
       "[100067 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_all = pd.DataFrame()\n",
    "for ticker in df.ticker.unique():\n",
    "    try:\n",
    "        port_temp = portfoy(ticker)\n",
    "        port_all = pd.concat([port_all, port_temp], axis=0, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(ticker, e)\n",
    "port_all = port_all.query(\"ticker != 'ALTIN.S1'\")\n",
    "port_all.reset_index(drop=True, inplace=True)\n",
    "# port_all.to_parquet(\"../streamlit/portfolyo/port_all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditions\n",
    "condition_ofsym = ((port_all['ticker'] == 'OFSYM') & (port_all['date'] >= '2023-08-16')) | (port_all['ticker'] != 'OFSYM')\n",
    "condition_adgyo = ((port_all['ticker'] == 'ADGYO') & (port_all['date'] >= '2023-09-21')) | (port_all['ticker'] != 'ADGYO')\n",
    "\n",
    "# Combine the conditions and filter the DataFrame\n",
    "port_all = port_all[condition_ofsym & condition_adgyo]\n",
    "# port_all.to_parquet(\"port_all.parquet\")\n",
    "\n",
    "selected_col = [\"date\",\"ticker\",\"h_q\",\"a_p_b\",'d_q_c',\"open\",\"close\",\"d_%\",'a_%', 'a_a_b', 't_v',\"d_r_p\", 'a_r_p',\"d_ur_p\", 'a_ur_p',\"d_p\",\"a_p\"]\n",
    "hisse_gunluk = port_all[selected_col]\n",
    "hisse_gunluk.to_parquet(\"hisse_gunluk.parquet\")\n",
    "\n",
    "selected_col = [\"date\",\"ticker\",\"h_q\",\"a_p_b\",'d_q_c',\"open\",\"close\",\"d_%\",'a_%', 'd_a_b',\"d_a_s\", 't_v',\"d_r_p\", 'a_r_p',\"d_ur_p\", 'a_ur_p']\n",
    "gunluk_ozet_raw = port_all[selected_col]\n",
    "\n",
    "# Group by business week\n",
    "gunluk_ozet = gunluk_ozet_raw.groupby(pd.Grouper(key=\"date\",freq='D')).agg({\n",
    "    \"d_a_b\": 'sum',\n",
    "    \"d_a_s\":'sum',\n",
    "    \"t_v\": 'sum',\n",
    "    \"d_r_p\": 'sum',\n",
    "    \"d_ur_p\": 'sum',\n",
    "    \"a_r_p\": 'sum',\n",
    "    \"a_ur_p\": 'sum',\n",
    "}).reset_index()\n",
    "gunluk_ozet = gunluk_ozet[gunluk_ozet[\"date\"].isin(tvdata[\"date\"].unique())]\n",
    "gunluk_ozet[\"d_a_c\"] = - gunluk_ozet[\"d_a_b\"] + gunluk_ozet[\"d_a_s\"]\n",
    "gunluk_ozet[\"d_a_c\"] = gunluk_ozet[\"d_a_c\"].round(2)\n",
    "gunluk_ozet[\"t_v\"] = gunluk_ozet[\"t_v\"].round(2)\n",
    "gunluk_ozet.insert(3,\"t_v_y\",gunluk_ozet[\"t_v\"].shift(1))\n",
    "gunluk_ozet.loc[0,\"t_v_y\"] = gunluk_ozet.loc[0,\"d_a_b\"]\n",
    "\n",
    "gunluk_ozet[\"d_r_p\"] = gunluk_ozet[\"d_r_p\"].round(2)\n",
    "gunluk_ozet[\"d_ur_p\"] = gunluk_ozet[\"d_ur_p\"].round(2)\n",
    "\n",
    "gunluk_ozet = gunluk_ozet.merge(cum_inv_df, on=\"date\", how=\"left\")\n",
    "gunluk_ozet.rename(columns={\"cum_inv\": \"a_inv\"}, inplace=True)\n",
    "gunluk_ozet.insert(9,\"d_inv\",gunluk_ozet[\"a_inv\"].diff())\n",
    "gunluk_ozet.loc[0,\"d_inv\"] = gunluk_ozet.loc[0,\"a_inv\"]\n",
    "gunluk_ozet[\"d_inv\"] = gunluk_ozet[\"d_inv\"].astype(int)\n",
    "\n",
    "gunluk_ozet.loc[1:,\"t_v_y\"] = gunluk_ozet.loc[1:,\"t_v_y\"] + gunluk_ozet.loc[1:,\"d_inv\"]\n",
    "gunluk_ozet.insert(4,\"d_%\",(round(gunluk_ozet[\"t_v\"] / gunluk_ozet[\"t_v_y\"],4) - 1) * 100)\n",
    "\n",
    "gunluk_ozet[\"d_b\"] = gunluk_ozet[\"d_inv\"] + (gunluk_ozet[\"d_a_c\"])\n",
    "gunluk_ozet[\"a_b\"] = gunluk_ozet[\"d_b\"].cumsum()\n",
    "\n",
    "gunluk_ozet[\"a_r_p\"] = gunluk_ozet[\"a_r_p\"].round(2)\n",
    "gunluk_ozet[\"a_ur_p\"] = gunluk_ozet[\"a_ur_p\"].round(2)\n",
    "gunluk_ozet[\"d_p\"] = gunluk_ozet[\"d_r_p\"] + gunluk_ozet[\"d_ur_p\"]\n",
    "gunluk_ozet[\"d_p_y\"] = round(gunluk_ozet[\"d_p\"] / gunluk_ozet[\"t_v\"],4) * 100\n",
    "\n",
    "# gunluk_ozet.to_parquet(\"gunluk_ozet.parquet\")\n",
    "\n",
    "\n",
    "selected_col = [\"date\",\"ticker\",\"h_q\",\"a_p_b\",'d_q_c',\"open\",\"close\",\"d_%\",'a_%', 'd_a_b',\"d_a_s\", 't_v',\"d_r_p\", 'a_r_p',\"d_ur_p\", 'a_ur_p',\"d_p\",\"a_p\"]\n",
    "haftalık_data = port_all[selected_col]\n",
    "def business_week(date):\n",
    "    # If the date is a Monday, return the date itself.\n",
    "    if date.weekday() == 0:  \n",
    "        return date\n",
    "    # Otherwise, return the date of the nearest past Monday.\n",
    "    else:\n",
    "        return date - pd.Timedelta(days=date.weekday())\n",
    "\n",
    "# Group by business week\n",
    "haftalık_ozet = haftalık_data.groupby([haftalık_data['date'].apply(business_week)]).agg({\n",
    "    \"d_a_b\": 'sum',\n",
    "    \"d_a_s\":'sum',\n",
    "    \"t_v\": 'sum',\n",
    "    \"d_r_p\": 'sum',\n",
    "    \"d_ur_p\": 'sum',\n",
    "    \"a_r_p\": 'sum',\n",
    "    \"a_ur_p\": 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "haftalık_ozet = haftalık_ozet[haftalık_ozet[\"date\"].isin(tvdata[\"date\"].unique())]\n",
    "haftalık_ozet[\"d_a_c\"] = - haftalık_ozet[\"d_a_b\"] + haftalık_ozet[\"d_a_s\"]\n",
    "haftalık_ozet[\"d_a_c\"] = haftalık_ozet[\"d_a_c\"].round(2)\n",
    "haftalık_ozet[\"t_v\"] = haftalık_ozet[\"t_v\"].round(2)\n",
    "haftalık_ozet.insert(3,\"t_v_y\",haftalık_ozet[\"t_v\"].shift(1))\n",
    "haftalık_ozet.loc[0,\"t_v_y\"] = haftalık_ozet.loc[0,\"d_a_b\"]\n",
    "\n",
    "haftalık_ozet[\"d_r_p\"] = haftalık_ozet[\"d_r_p\"].round(2)\n",
    "haftalık_ozet[\"d_ur_p\"] = haftalık_ozet[\"d_ur_p\"].round(2)\n",
    "\n",
    "haftalık_ozet = haftalık_ozet.merge(cum_inv_df, on=\"date\", how=\"left\")\n",
    "haftalık_ozet.rename(columns={\"cum_inv\": \"a_inv\"}, inplace=True)\n",
    "haftalık_ozet.insert(9,\"d_inv\",haftalık_ozet[\"a_inv\"].diff())\n",
    "haftalık_ozet.loc[0,\"d_inv\"] = haftalık_ozet.loc[0,\"a_inv\"]\n",
    "haftalık_ozet[\"d_inv\"] = haftalık_ozet[\"d_inv\"].astype(int)\n",
    "\n",
    "haftalık_ozet.loc[1:,\"t_v_y\"] = haftalık_ozet.loc[1:,\"t_v_y\"] + haftalık_ozet.loc[1:,\"d_inv\"]\n",
    "haftalık_ozet.insert(4,\"d_%\",(round(haftalık_ozet[\"t_v\"] / haftalık_ozet[\"t_v_y\"],4) - 1) * 100)\n",
    "\n",
    "haftalık_ozet[\"d_b\"] = haftalık_ozet[\"d_inv\"] + (haftalık_ozet[\"d_a_c\"])\n",
    "haftalık_ozet[\"a_b\"] = haftalık_ozet[\"d_b\"].cumsum()\n",
    "\n",
    "haftalık_ozet[\"a_r_p\"] = haftalık_ozet[\"a_r_p\"].round(2)\n",
    "haftalık_ozet[\"a_ur_p\"] = haftalık_ozet[\"a_ur_p\"].round(2)\n",
    "haftalık_ozet[\"d_p\"] = haftalık_ozet[\"d_r_p\"] + haftalık_ozet[\"d_ur_p\"]\n",
    "haftalık_ozet[\"d_p_y\"] = round(haftalık_ozet[\"d_p\"] / haftalık_ozet[\"t_v\"],4) * 100\n",
    "\n",
    "# haftalık_ozet\n",
    "# haftalık_ozet.to_parquet(\"haftalık_ozet.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28-09-2023'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "now = datetime.now()\n",
    "if now.weekday() >= 5:  # 5: Saturday, 6: Sunday\n",
    "    # If today is Saturday, subtract 1 day to get Friday's data\n",
    "    # If today is Sunday, subtract 2 days to get Friday's data\n",
    "    days_to_subtract = now.weekday() - 4\n",
    "    today_str = (now - timedelta(days=days_to_subtract)).strftime(\"%d-%m-%Y\")\n",
    "else:\n",
    "    # For weekdays, if the current time is before 18:00, use yesterday's date\n",
    "    if now.hour < 18:\n",
    "        today_str = (now - timedelta(days=1)).strftime(\"%d-%m-%Y\")\n",
    "    else:\n",
    "        # If the current time is 18:00 or later, use today's date\n",
    "        today_str = now.strftime(\"%d-%m-%Y\")\n",
    "today_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplam_buyukluk = port_all.query(\"date == @today_str\").t_v.sum()\n",
    "gunluk_net = gunluk_ozet.query(\"date == @today_str\").d_p.values[0]\n",
    "gunluk_yuzde = gunluk_ozet.query(\"date == @today_str\").d_p_y.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230929'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "tv = TvDatafeed()\n",
    "\n",
    "def fetch_data(ticker):\n",
    "    data = tv.get_hist(symbol=ticker, exchange='BIST', interval=Interval.in_daily, n_bars=200)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-07 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>5001.9702</td>\n",
       "      <td>5014.5698</td>\n",
       "      <td>4773.3799</td>\n",
       "      <td>4827.0400</td>\n",
       "      <td>5.669737e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-08 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>4823.3301</td>\n",
       "      <td>4859.2700</td>\n",
       "      <td>4711.4302</td>\n",
       "      <td>4855.9199</td>\n",
       "      <td>5.058030e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>4875.2202</td>\n",
       "      <td>5015.2300</td>\n",
       "      <td>4871.2798</td>\n",
       "      <td>5005.2998</td>\n",
       "      <td>4.786662e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-12 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>5057.5298</td>\n",
       "      <td>5222.5498</td>\n",
       "      <td>5057.5298</td>\n",
       "      <td>5193.2998</td>\n",
       "      <td>7.118074e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-13 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>5212.5801</td>\n",
       "      <td>5299.3301</td>\n",
       "      <td>5179.8198</td>\n",
       "      <td>5256.1899</td>\n",
       "      <td>6.766963e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-22 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8035.0498</td>\n",
       "      <td>8094.0298</td>\n",
       "      <td>7981.2300</td>\n",
       "      <td>8039.1802</td>\n",
       "      <td>4.187311e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-25 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8105.3599</td>\n",
       "      <td>8311.1602</td>\n",
       "      <td>8096.9502</td>\n",
       "      <td>8304.8301</td>\n",
       "      <td>4.864111e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-26 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8368.5098</td>\n",
       "      <td>8389.6797</td>\n",
       "      <td>8240.8301</td>\n",
       "      <td>8242.2598</td>\n",
       "      <td>5.966519e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-27 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8275.1396</td>\n",
       "      <td>8298.6504</td>\n",
       "      <td>8170.8901</td>\n",
       "      <td>8213.7598</td>\n",
       "      <td>4.426915e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-28 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8235.7900</td>\n",
       "      <td>8288.4805</td>\n",
       "      <td>8187.9600</td>\n",
       "      <td>8218.7402</td>\n",
       "      <td>4.110880e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         symbol       open       high        low      close   \n",
       "datetime                                                                      \n",
       "2022-12-07 09:00:00  BIST:XU100  5001.9702  5014.5698  4773.3799  4827.0400  \\\n",
       "2022-12-08 09:00:00  BIST:XU100  4823.3301  4859.2700  4711.4302  4855.9199   \n",
       "2022-12-09 09:00:00  BIST:XU100  4875.2202  5015.2300  4871.2798  5005.2998   \n",
       "2022-12-12 09:00:00  BIST:XU100  5057.5298  5222.5498  5057.5298  5193.2998   \n",
       "2022-12-13 09:00:00  BIST:XU100  5212.5801  5299.3301  5179.8198  5256.1899   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "2023-09-22 09:00:00  BIST:XU100  8035.0498  8094.0298  7981.2300  8039.1802   \n",
       "2023-09-25 09:00:00  BIST:XU100  8105.3599  8311.1602  8096.9502  8304.8301   \n",
       "2023-09-26 09:00:00  BIST:XU100  8368.5098  8389.6797  8240.8301  8242.2598   \n",
       "2023-09-27 09:00:00  BIST:XU100  8275.1396  8298.6504  8170.8901  8213.7598   \n",
       "2023-09-28 09:00:00  BIST:XU100  8235.7900  8288.4805  8187.9600  8218.7402   \n",
       "\n",
       "                           volume  \n",
       "datetime                           \n",
       "2022-12-07 09:00:00  5.669737e+09  \n",
       "2022-12-08 09:00:00  5.058030e+09  \n",
       "2022-12-09 09:00:00  4.786662e+09  \n",
       "2022-12-12 09:00:00  7.118074e+09  \n",
       "2022-12-13 09:00:00  6.766963e+09  \n",
       "...                           ...  \n",
       "2023-09-22 09:00:00  4.187311e+09  \n",
       "2023-09-25 09:00:00  4.864111e+09  \n",
       "2023-09-26 09:00:00  5.966519e+09  \n",
       "2023-09-27 09:00:00  4.426915e+09  \n",
       "2023-09-28 09:00:00  4.110880e+09  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data(\"XU100\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
