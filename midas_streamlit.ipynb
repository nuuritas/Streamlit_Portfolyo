{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime as dt\n",
    "import os \n",
    "import json\n",
    "import requests\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from tvDatafeed import TvDatafeed, Interval\n",
    "tv = TvDatafeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fintables Sektörler ve Şirketler Güncelleniyor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fintables Şirketler: 100%|██████████| 44/44 [00:03<00:00, 13.29it/s]\n",
      "100%|██████████| 11/11 [00:06<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_sector_wide(data, sector_name):\n",
    "    rename_dict = {\n",
    "        \"Sektör Ortalamaları\": \"Metrics\",\n",
    "        \"F/K\": \"fk\",\n",
    "        \"PD/DD\": \"pd_dd\",\n",
    "        \"FD/FAVÖK\": \"fd_favok\"\n",
    "    }\n",
    "    \n",
    "    data = data.rename(columns=rename_dict)\n",
    "\n",
    "    \n",
    "    new_columns = {\n",
    "        \"BIST 100\": \"bist100\",\n",
    "        \"Aritmetik Ortalama\": \"ao\",\n",
    "        \"Ağırlıklı Ortalama\": \"wo\",\n",
    "        \"Medyan\": \"median\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    wide_df = pd.DataFrame()\n",
    "    wide_df['sector_name'] = [sector_name]\n",
    "\n",
    "    for metric, prefix in new_columns.items():\n",
    "        for column in ['fk', 'pd_dd', 'fd_favok']:\n",
    "            col_name = f\"{prefix}_{column}\"\n",
    "            if sector_name == 'bankacilik' and column == 'fd_favok':\n",
    "                wide_df[col_name] = np.nan\n",
    "            else:\n",
    "                wide_df[col_name] = data[data['Metrics'] == metric][column].values\n",
    "\n",
    "    return wide_df\n",
    "\n",
    "# Function to convert 'Piyasa Değeri' to numerical value\n",
    "def convert_piyasa_degeri(value):\n",
    "    value = value.replace('₺', '').strip()\n",
    "    if 'mr' in value:\n",
    "        value = float(value.replace('mr', '')) * 1e3  # convert to billion\n",
    "    elif 'mn' in value:\n",
    "        value = float(value.replace('mn', ''))  # convert to million\n",
    "    return value\n",
    "\n",
    "def get_sector(sector_name):\n",
    "\n",
    "    headers = {\n",
    "        'authority': 'fintables.com',\n",
    "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'accept-language': 'en-US,en;q=0.9,tr;q=0.8,tr-TR;q=0.7',\n",
    "        'cache-control': 'no-cache',\n",
    "        'cookie': '_gid=GA1.2.50961081.1690710140; _gcl_au=1.1.518997462.1690710149; auth-token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoyMTIyNzEwMTk3LCJpYXQiOjE2OTA3MTAxOTcsImp0aSI6IjQ2NGI0YTIxYjY3ZjQ3ZDY4MmEwYjg5NWE3ZjlkMWE4IiwidXNlcl9pZCI6MTEyNzMzfQ.Bh3945i5RjYHblFOyoN_e9oqVmQcOUukFo8GqXp5wtg; _gat_UA-72451211-3=1; _ga=GA1.2.1134893438.1690710140; _ga_22JQCWWZZJ=GS1.1.1690710149.1.1.1690711335.20.0.0',\n",
    "        'dnt': '1',\n",
    "        'pragma': 'no-cache',\n",
    "        'sec-ch-ua': '\"Not.A/Brand\";v=\"8\", \"Chromium\";v=\"114\", \"Google Chrome\";v=\"114\"',\n",
    "        'sec-ch-ua-mobile': '?0',\n",
    "        'sec-ch-ua-platform': '\"macOS\"',\n",
    "        'sec-fetch-dest': 'document',\n",
    "        'sec-fetch-mode': 'navigate',\n",
    "        'sec-fetch-site': 'same-origin',\n",
    "        'sec-fetch-user': '?1',\n",
    "        'upgrade-insecure-requests': '1',\n",
    "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    response = requests.get(f'https://fintables.com/sektorler/{sector_name}', headers=headers)\n",
    "\n",
    "    # The content of the response\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    sektor_ozet = soup.find_all('table', class_=\"min-w-full\")[0]\n",
    "    sektor_ozet2 = str(sektor_ozet).replace(\".\",\"\").replace(',', '.')\n",
    "    sektor_ozet_df = pd.read_html(str(sektor_ozet2))[0]\n",
    "    sektor_ozet_wide = convert_sector_wide(sektor_ozet_df, sector_name)\n",
    "    \n",
    "    my_table = soup.find_all('table', class_=\"min-w-full\")[1]\n",
    "    my_table2 = str(my_table).replace(\".\",\"\").replace(',', '.')\n",
    "    df = pd.read_html(str(my_table2))[0]\n",
    "    \n",
    "    df['Piyasa Değeri'] = df['Piyasa Değeri'].apply(convert_piyasa_degeri)\n",
    "    #df['Piyasa Değeri'] = df['Piyasa Değeri'].astype(int)\n",
    "    df[\"sector\"] = sector_name\n",
    "\n",
    "    return sektor_ozet_wide, df\n",
    "\n",
    "def get_sector_multiple(sector_names):\n",
    "    ozet_list = []\n",
    "    sirket_list = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        for sektor_ozet,tum_sirketler in tqdm(executor.map(get_sector, sector_names), total=len(sector_names), desc=\"Fintables Şirketler\"):\n",
    "            try:\n",
    "                sirket_list.append(tum_sirketler)\n",
    "                ozet_list.append(sektor_ozet)\n",
    "            except Exception as e:\n",
    "                print(\"Error: \", e)\n",
    "    sirket_df = pd.concat(sirket_list, axis=0, ignore_index=True)\n",
    "    ozet_df = pd.concat(ozet_list, axis=0, ignore_index=True)\n",
    "\n",
    "    sirket_df['Şirket Kodu'] = sirket_df['Şirket Kodu'].str[:-7]\n",
    "    # sirket_df['Piyasa Değeri'] = sirket_df['Piyasa Değeri'].astype(float)\n",
    "\n",
    "    sirket_df.columns = ['sirket_kodu', 'piyasa_degeri', 'fk', 'pd_dd', 'fd_favok', 'sector']\n",
    "    return ozet_df, sirket_df\n",
    "\n",
    "sector_names = json.load(open('sector_names.json',encoding=\"utf-8\"))\n",
    "\n",
    "print(\"Fintables Sektörler ve Şirketler Güncelleniyor\")\n",
    "ozet_df, sirket_df = get_sector_multiple(sector_names)\n",
    "\n",
    "all_tickers = sirket_df['sirket_kodu'].unique()\n",
    "all_tickers = list(all_tickers[:10])\n",
    "all_tickers.append('XU100')\n",
    "data_list = []\n",
    "\n",
    "def fetch_data(ticker):\n",
    "    data = tv.get_hist(symbol=ticker, exchange='BIST', interval=Interval.in_daily, n_bars=200)\n",
    "    return data\n",
    "\n",
    "# Use a ThreadPoolExecutor to fetch data in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Wrap the executor and the ticker list with tqdm for a progress bar\n",
    "    data_list = list(tqdm(executor.map(fetch_data, all_tickers), total=len(all_tickers)))\n",
    "\n",
    "\n",
    "data = pd.concat(data_list).reset_index()\n",
    "data[\"symbol\"] = data[\"symbol\"].str[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_no_sell(grouped):\n",
    "    grouped.insert(2,\"d_q_s\", 0)\n",
    "    grouped.insert(3,\"d_q_c\",grouped[\"d_q_b\"] - grouped[\"d_q_s\"])\n",
    "    grouped.insert(5,\"d_a_s\",0)\n",
    "    grouped[\"d_p_s\"] = 0\n",
    "\n",
    "    grouped = grouped.fillna(0)\n",
    "    grouped[\"h_q\"] = grouped[\"d_q_c\"].cumsum()\n",
    "    \n",
    "\n",
    "    grouped[\"a_a_b\"] = grouped[\"d_a_b\"].cumsum() \n",
    "    grouped[\"a_a_s\"] = grouped[\"d_a_s\"].cumsum() \n",
    "\n",
    "    grouped[\"a_p_b\"] = grouped[\"a_a_b\"] / grouped[\"h_q\"]\n",
    "\n",
    "    grouped[\"a_p_b\"] = grouped[\"a_p_b\"].apply(lambda x: round(x,2))\n",
    "    grouped[\"d_r_p\"] = 0\n",
    "    grouped[\"a_r_p\"] = 0\n",
    "    grouped.insert(9,\"h_a\",grouped[\"a_p_b\"] * grouped[\"h_q\"])\n",
    "    grouped[\"h_a\"] = grouped[\"h_a\"].apply(lambda x: round(x,2))\n",
    "    return grouped\n",
    "\n",
    "def p_buy_and_sell(grouped):\n",
    "    grouped = grouped.fillna(0)\n",
    "    grouped.insert(3,\"d_q_c\",grouped[\"d_q_b\"] - grouped[\"d_q_s\"])\n",
    "    grouped[\"h_q\"] = grouped[\"d_q_c\"].cumsum()\n",
    "    \n",
    "\n",
    "    grouped[\"a_a_b\"] = grouped[\"d_a_b\"].cumsum() \n",
    "    grouped[\"a_a_s\"] = grouped[\"d_a_s\"].cumsum() \n",
    "\n",
    "    grouped.loc[0,\"a_p_b\"] = grouped.loc[0,\"a_a_b\"] / grouped.loc[0,\"h_q\"]\n",
    "\n",
    "    for i, val in grouped.iterrows():\n",
    "        #Eğer tüm hisseler o gün satıldıysa, bir sonraki gündeki ortalama fiyat sadece yeni alınan hisselerin ortalaması olur.\n",
    "        #Eğer tüm hisseler o gün satıldıysa, ve o gün alım olmadıysa, ortalama önceki güne eşit olur.\n",
    "        if val[\"h_q\"] == 0:\n",
    "            if val[\"d_q_b\"] == 0:\n",
    "                grouped.loc[i,\"a_p_b\"] = grouped.loc[i-1,\"a_p_b\"]\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            #Eğer alış olmadıysa, eldeki maliyet değişmez.\n",
    "            if val[\"d_q_b\"] == 0:\n",
    "                grouped.loc[i,\"a_p_b\"] = grouped.loc[i-1,\"a_p_b\"]\n",
    "            else:\n",
    "                grouped.loc[i,\"a_p_b\"] = (grouped.loc[:i,\"d_a_b\"].sum() - grouped.loc[:i,\"d_a_s\"].sum()) / grouped.loc[i,\"h_q\"]\n",
    "            # grouped.loc[i,\"a_p_b\"] = val[\"a_a_b\"] / val[\"h_q\"]\n",
    "        if 0 in grouped.loc[:i,\"h_q\"].values:\n",
    "            \n",
    "            last_zero_index = grouped.loc[:i,\"h_q\"].tolist().index(0)\n",
    "            if val[\"d_q_b\"] != 0:\n",
    "                grouped.loc[i,\"a_p_b\"] = sum_product = grouped.loc[last_zero_index:i, \n",
    "                                        \"d_p_b\"].mul(grouped.loc[last_zero_index:i, \"d_q_b\"]).sum() / grouped.loc[last_zero_index:i,\"d_q_b\"].sum()\n",
    "        if val[\"d_q_s\"] > 0:\n",
    "            last_average_buy = grouped.loc[:i].query(\"d_p_b != 0\")[\"d_p_b\"].iloc[-1]\n",
    "            grouped.loc[i,\"d_r_p\"] = (val[\"d_p_s\"] - last_average_buy) * val[\"d_q_s\"]\n",
    "        else:\n",
    "            grouped.loc[i,\"d_r_p\"] = 0\n",
    "        grouped.loc[i,\"a_r_p\"] = grouped.loc[:i,\"d_r_p\"].sum()\n",
    "    \n",
    "    grouped[\"a_p_b\"] = grouped[\"a_p_b\"].apply(lambda x: round(x,2))\n",
    "        \n",
    "    grouped.insert(9,\"h_a\",grouped[\"a_p_b\"] * grouped[\"h_q\"])\n",
    "    grouped[\"h_a\"] = grouped[\"h_a\"].apply(lambda x: round(x,2))\n",
    "    return grouped\n",
    "\n",
    "def port_func1(ticker,df):\n",
    "    data = df.query(\"ticker == @ticker\")\n",
    "    data[\"date\"] = data[\"date\"].apply(lambda x: x.normalize())\n",
    "\n",
    "    df1 = data.groupby([\"date\", \"buy_sell\"]).agg({\n",
    "        \"quantity\": \"sum\",\n",
    "        \"trans_amount\": \"sum\",\n",
    "        \"price\": lambda x: (x * data.loc[x.index, \"quantity\"]).sum() / df.loc[x.index, \"quantity\"].sum()\n",
    "    }).unstack()\n",
    "\n",
    "    df1.columns = [\"_\".join(col).strip() for col in df1.columns.values]\n",
    "    df1 = df1.rename(columns={\n",
    "        \"quantity_Alış\": \"d_q_b\",\n",
    "        \"quantity_Satış\": \"d_q_s\",\n",
    "        \"trans_amount_Alış\": \"d_a_b\",\n",
    "        \"trans_amount_Satış\": \"d_a_s\",\n",
    "        \"price_Alış\": \"d_p_b\",\n",
    "        \"price_Satış\": \"d_p_s\"\n",
    "    }).reset_index()\n",
    "\n",
    "    ####Situation stock never sold:\n",
    "    if \"d_q_s\" not in df1.columns:\n",
    "        df2 = p_no_sell(df1)\n",
    "    else:\n",
    "        df2 = p_buy_and_sell(df1)\n",
    "    return ticker, df2\n",
    "\n",
    "    ticker, df3 = port_func1(ticker,df)\n",
    "\n",
    "def port_func2(ticker,df3):\n",
    "        min_date = df3[\"date\"].min()\n",
    "        if df3.loc[len(df3)-1,\"h_q\"] != 0:\n",
    "            max_date = dt.today()\n",
    "        else:\n",
    "            max_date = df3[\"date\"].max()\n",
    "        df4 = pd.DataFrame({'date': pd.date_range(start=min_date, end=max_date, freq='B').normalize()})\n",
    "        df4 = df4.merge(df3, on='date', how='left')\n",
    "        df4 = df4.fillna({\n",
    "                'd_q_b': 0,\n",
    "                'd_q_s': 0,\n",
    "                'd_a_b': 0,\n",
    "                'd_a_s': 0,\n",
    "                'd_p_b': 0,\n",
    "                'd_p_s': 0,\n",
    "                'd_q_c': 0,\n",
    "                \"d_r_p\": 0,\n",
    "            })\n",
    "        \n",
    "        df4 = df4.merge(tvdata.query(\"ticker == @ticker\")[[\"date\",\"open\",\"close\"]], on=[\"date\"],how=\"left\")\n",
    "        f_fill_col = [\"h_q\", \"a_a_b\",\"a_a_s\", \"a_p_b\", \"a_r_p\",\"close\",\"open\"] \n",
    "        #min, max, vol_ö\n",
    "        df4[f_fill_col] = df4[f_fill_col].ffill()\n",
    "        \n",
    "        df4 = df4.query(\"d_q_b + d_q_s + h_q > 0\")\n",
    "        # df4 = df4.fillna(0)\n",
    "        df4[\"h_a\"] = df4[\"h_q\"] * df4[\"a_p_b\"]\n",
    "        df4['t_v'] = df4['h_q'] * df4['close']\n",
    "        \n",
    "        df4['a_ur_p'] = df4['t_v'] - df4['h_a']\n",
    "        df4['a_ur_p'] = np.where(df4['h_q'] == 0, 0, df4['a_ur_p'])\n",
    "        df4[\"d_ur_p\"] = (df4[\"close\"] - df4[\"open\"]) * df4[\"h_q\"]\n",
    "        df4[\"d_p\"] = df4[\"d_ur_p\"] + df4[\"d_r_p\"]\n",
    "        df4[\"a_p\"] = df4[\"a_ur_p\"] + df4[\"a_r_p\"]\n",
    "        df4[\"d_%\"] = (round(df4[\"close\"] / df4[\"open\"],3) - 1) * 100\n",
    "        df4[\"a_%\"] = (round(df4[\"close\"] / df4[\"a_p_b\"],3) - 1) * 100\n",
    "        df4.reset_index(drop=True, inplace=True)\n",
    "        df4[\"d_p_b\"] = df4[\"d_p_b\"].apply(lambda x: round(x,2))\n",
    "        df4[\"open\"] = df4[\"open\"].apply(lambda x: round(x,2))\n",
    "        df4.insert(1, 'ticker', ticker)\n",
    "        return df4    \n",
    "    \n",
    "def portfoy(ticker):\n",
    "    ticker, df3 = port_func1(ticker,df)\n",
    "    df4 = port_func2(ticker,df3)\n",
    "    return df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"midas_df.parquet\")\n",
    "cum_inv_df = pd.read_parquet(\"midas_cum_inv_df.parquet\")\n",
    "tvdata = pd.read_parquet(\"output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_all = pd.DataFrame()\n",
    "for ticker in df.ticker.unique():\n",
    "    try:\n",
    "        port_temp = portfoy(ticker)\n",
    "        port_all = pd.concat([port_all, port_temp], axis=0, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(ticker, e)\n",
    "port_all = port_all.query(\"ticker != 'ALTIN.S1'\")\n",
    "port_all.reset_index(drop=True, inplace=True)\n",
    "# port_all.to_parquet(\"../streamlit/portfolyo/port_all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>d_a_b</th>\n",
       "      <th>d_a_s</th>\n",
       "      <th>t_v_y</th>\n",
       "      <th>t_v</th>\n",
       "      <th>d_r_p</th>\n",
       "      <th>d_ur_p</th>\n",
       "      <th>a_r_p</th>\n",
       "      <th>a_ur_p</th>\n",
       "      <th>d_inv</th>\n",
       "      <th>d_a_c</th>\n",
       "      <th>a_inv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2023-09-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95660.78</td>\n",
       "      <td>96790.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.38</td>\n",
       "      <td>348.25</td>\n",
       "      <td>14010.041177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  d_a_b  d_a_s     t_v_y       t_v  d_r_p  d_ur_p   a_r_p  \\\n",
       "63 2023-09-29    0.0    0.0  95660.78  96790.62    0.0  399.38  348.25   \n",
       "\n",
       "          a_ur_p  d_inv  d_a_c  a_inv  \n",
       "63  14010.041177    NaN    0.0    NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show rows with NaN values\n",
    "\n",
    "gunluk_ozet[gunluk_ozet.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Streamlit_Portfolyo/midas_streamlit.ipynb Hücre 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfriendly-capybara-qgr4x6qqv5x3xj7/workspaces/Streamlit_Portfolyo/midas_streamlit.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m gunluk_ozet\u001b[39m.\u001b[39minsert(\u001b[39m9\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39md_inv\u001b[39m\u001b[39m\"\u001b[39m,gunluk_ozet[\u001b[39m\"\u001b[39m\u001b[39ma_inv\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mdiff())\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfriendly-capybara-qgr4x6qqv5x3xj7/workspaces/Streamlit_Portfolyo/midas_streamlit.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m gunluk_ozet\u001b[39m.\u001b[39mloc[\u001b[39m0\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39md_inv\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m gunluk_ozet\u001b[39m.\u001b[39mloc[\u001b[39m0\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39ma_inv\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bfriendly-capybara-qgr4x6qqv5x3xj7/workspaces/Streamlit_Portfolyo/midas_streamlit.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m gunluk_ozet[\u001b[39m\"\u001b[39m\u001b[39md_inv\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m gunluk_ozet[\u001b[39m\"\u001b[39;49m\u001b[39md_inv\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfriendly-capybara-qgr4x6qqv5x3xj7/workspaces/Streamlit_Portfolyo/midas_streamlit.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m gunluk_ozet\u001b[39m.\u001b[39mloc[\u001b[39m1\u001b[39m:,\u001b[39m\"\u001b[39m\u001b[39mt_v_y\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m gunluk_ozet\u001b[39m.\u001b[39mloc[\u001b[39m1\u001b[39m:,\u001b[39m\"\u001b[39m\u001b[39mt_v_y\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m gunluk_ozet\u001b[39m.\u001b[39mloc[\u001b[39m1\u001b[39m:,\u001b[39m\"\u001b[39m\u001b[39md_inv\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bfriendly-capybara-qgr4x6qqv5x3xj7/workspaces/Streamlit_Portfolyo/midas_streamlit.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m gunluk_ozet\u001b[39m.\u001b[39minsert(\u001b[39m4\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39md_\u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m,(\u001b[39mround\u001b[39m(gunluk_ozet[\u001b[39m\"\u001b[39m\u001b[39mt_v\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m/\u001b[39m gunluk_ozet[\u001b[39m\"\u001b[39m\u001b[39mt_v_y\u001b[39m\u001b[39m\"\u001b[39m],\u001b[39m4\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:6532\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6528\u001b[0m     results \u001b[39m=\u001b[39m [ser\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy) \u001b[39mfor\u001b[39;00m _, ser \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()]\n\u001b[1;32m   6530\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6531\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6532\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   6533\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[39m=\u001b[39mnew_data\u001b[39m.\u001b[39maxes)\n\u001b[1;32m   6534\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[39melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    412\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    415\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    416\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    417\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    418\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    419\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[1;32m    420\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 354\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    355\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    357\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[0;32m--> 616\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m    618\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    620\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[1;32m    237\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    239\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    240\u001b[0m     \u001b[39m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    182\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     values \u001b[39m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    185\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:101\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mensure_string_array(\n\u001b[1;32m     97\u001b[0m         arr, skipna\u001b[39m=\u001b[39mskipna, convert_na_value\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     )\u001b[39m.\u001b[39mreshape(shape)\n\u001b[1;32m    100\u001b[0m \u001b[39melif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(arr\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating) \u001b[39mand\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39miu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m _astype_float_to_int_nansafe(arr, dtype, copy)\n\u001b[1;32m    103\u001b[0m \u001b[39melif\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[39m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[39m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m lib\u001b[39m.\u001b[39mis_np_dtype(dtype, \u001b[39m\"\u001b[39m\u001b[39mM\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:146\u001b[0m, in \u001b[0;36m_astype_float_to_int_nansafe\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(values)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 146\u001b[0m     \u001b[39mraise\u001b[39;00m IntCastingNaNError(\n\u001b[1;32m    147\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    150\u001b[0m     \u001b[39m# GH#45151\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (values \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "# Define the conditions\n",
    "condition_ofsym = ((port_all['ticker'] == 'OFSYM') & (port_all['date'] >= '2023-08-16')) | (port_all['ticker'] != 'OFSYM')\n",
    "condition_adgyo = ((port_all['ticker'] == 'ADGYO') & (port_all['date'] >= '2023-09-21')) | (port_all['ticker'] != 'ADGYO')\n",
    "\n",
    "# Combine the conditions and filter the DataFrame\n",
    "port_all = port_all[condition_ofsym & condition_adgyo]\n",
    "# port_all.to_parquet(\"port_all.parquet\")\n",
    "\n",
    "selected_col = [\"date\",\"ticker\",\"h_q\",\"a_p_b\",'d_q_c',\"open\",\"close\",\"d_%\",'a_%', 'a_a_b', 't_v',\"d_r_p\", 'a_r_p',\"d_ur_p\", 'a_ur_p',\"d_p\",\"a_p\"]\n",
    "hisse_gunluk = port_all[selected_col]\n",
    "hisse_gunluk.to_parquet(\"hisse_gunluk.parquet\")\n",
    "\n",
    "selected_col = [\"date\",\"ticker\",\"h_q\",\"a_p_b\",'d_q_c',\"open\",\"close\",\"d_%\",'a_%', 'd_a_b',\"d_a_s\", 't_v',\"d_r_p\", 'a_r_p',\"d_ur_p\", 'a_ur_p']\n",
    "gunluk_ozet_raw = port_all[selected_col]\n",
    "\n",
    "# Group by business week\n",
    "gunluk_ozet = gunluk_ozet_raw.groupby(pd.Grouper(key=\"date\",freq='D')).agg({\n",
    "    \"d_a_b\": 'sum',\n",
    "    \"d_a_s\":'sum',\n",
    "    \"t_v\": 'sum',\n",
    "    \"d_r_p\": 'sum',\n",
    "    \"d_ur_p\": 'sum',\n",
    "    \"a_r_p\": 'sum',\n",
    "    \"a_ur_p\": 'sum',\n",
    "}).reset_index()\n",
    "gunluk_ozet = gunluk_ozet[gunluk_ozet[\"date\"].isin(tvdata[\"date\"].unique())]\n",
    "gunluk_ozet[\"d_a_c\"] = - gunluk_ozet[\"d_a_b\"] + gunluk_ozet[\"d_a_s\"]\n",
    "gunluk_ozet[\"d_a_c\"] = gunluk_ozet[\"d_a_c\"].round(2)\n",
    "gunluk_ozet[\"t_v\"] = gunluk_ozet[\"t_v\"].round(2)\n",
    "gunluk_ozet.insert(3,\"t_v_y\",gunluk_ozet[\"t_v\"].shift(1))\n",
    "gunluk_ozet.loc[0,\"t_v_y\"] = gunluk_ozet.loc[0,\"d_a_b\"]\n",
    "\n",
    "gunluk_ozet[\"d_r_p\"] = gunluk_ozet[\"d_r_p\"].round(2)\n",
    "gunluk_ozet[\"d_ur_p\"] = gunluk_ozet[\"d_ur_p\"].round(2)\n",
    "\n",
    "gunluk_ozet = gunluk_ozet.merge(cum_inv_df, on=\"date\", how=\"left\")\n",
    "gunluk_ozet.rename(columns={\"cum_inv\": \"a_inv\"}, inplace=True)\n",
    "gunluk_ozet.insert(9,\"d_inv\",gunluk_ozet[\"a_inv\"].diff())\n",
    "gunluk_ozet.loc[0,\"d_inv\"] = gunluk_ozet.loc[0,\"a_inv\"]\n",
    "gunluk_ozet[\"d_inv\"] = gunluk_ozet[\"d_inv\"].astype(int)\n",
    "\n",
    "gunluk_ozet.loc[1:,\"t_v_y\"] = gunluk_ozet.loc[1:,\"t_v_y\"] + gunluk_ozet.loc[1:,\"d_inv\"]\n",
    "gunluk_ozet.insert(4,\"d_%\",(round(gunluk_ozet[\"t_v\"] / gunluk_ozet[\"t_v_y\"],4) - 1) * 100)\n",
    "\n",
    "gunluk_ozet[\"d_b\"] = gunluk_ozet[\"d_inv\"] + (gunluk_ozet[\"d_a_c\"])\n",
    "gunluk_ozet[\"a_b\"] = gunluk_ozet[\"d_b\"].cumsum()\n",
    "\n",
    "gunluk_ozet[\"a_r_p\"] = gunluk_ozet[\"a_r_p\"].round(2)\n",
    "gunluk_ozet[\"a_ur_p\"] = gunluk_ozet[\"a_ur_p\"].round(2)\n",
    "gunluk_ozet[\"d_p\"] = gunluk_ozet[\"d_r_p\"] + gunluk_ozet[\"d_ur_p\"]\n",
    "gunluk_ozet[\"d_p_y\"] = round(gunluk_ozet[\"d_p\"] / gunluk_ozet[\"t_v\"],4) * 100\n",
    "\n",
    "# gunluk_ozet.to_parquet(\"gunluk_ozet.parquet\")\n",
    "\n",
    "\n",
    "selected_col = [\"date\",\"ticker\",\"h_q\",\"a_p_b\",'d_q_c',\"open\",\"close\",\"d_%\",'a_%', 'd_a_b',\"d_a_s\", 't_v',\"d_r_p\", 'a_r_p',\"d_ur_p\", 'a_ur_p',\"d_p\",\"a_p\"]\n",
    "haftalık_data = port_all[selected_col]\n",
    "def business_week(date):\n",
    "    # If the date is a Monday, return the date itself.\n",
    "    if date.weekday() == 0:  \n",
    "        return date\n",
    "    # Otherwise, return the date of the nearest past Monday.\n",
    "    else:\n",
    "        return date - pd.Timedelta(days=date.weekday())\n",
    "\n",
    "# Group by business week\n",
    "haftalık_ozet = haftalık_data.groupby([haftalık_data['date'].apply(business_week)]).agg({\n",
    "    \"d_a_b\": 'sum',\n",
    "    \"d_a_s\":'sum',\n",
    "    \"t_v\": 'sum',\n",
    "    \"d_r_p\": 'sum',\n",
    "    \"d_ur_p\": 'sum',\n",
    "    \"a_r_p\": 'sum',\n",
    "    \"a_ur_p\": 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "haftalık_ozet = haftalık_ozet[haftalık_ozet[\"date\"].isin(tvdata[\"date\"].unique())]\n",
    "haftalık_ozet[\"d_a_c\"] = - haftalık_ozet[\"d_a_b\"] + haftalık_ozet[\"d_a_s\"]\n",
    "haftalık_ozet[\"d_a_c\"] = haftalık_ozet[\"d_a_c\"].round(2)\n",
    "haftalık_ozet[\"t_v\"] = haftalık_ozet[\"t_v\"].round(2)\n",
    "haftalık_ozet.insert(3,\"t_v_y\",haftalık_ozet[\"t_v\"].shift(1))\n",
    "haftalık_ozet.loc[0,\"t_v_y\"] = haftalık_ozet.loc[0,\"d_a_b\"]\n",
    "\n",
    "haftalık_ozet[\"d_r_p\"] = haftalık_ozet[\"d_r_p\"].round(2)\n",
    "haftalık_ozet[\"d_ur_p\"] = haftalık_ozet[\"d_ur_p\"].round(2)\n",
    "\n",
    "haftalık_ozet = haftalık_ozet.merge(cum_inv_df, on=\"date\", how=\"left\")\n",
    "haftalık_ozet.rename(columns={\"cum_inv\": \"a_inv\"}, inplace=True)\n",
    "haftalık_ozet.insert(9,\"d_inv\",haftalık_ozet[\"a_inv\"].diff())\n",
    "haftalık_ozet.loc[0,\"d_inv\"] = haftalık_ozet.loc[0,\"a_inv\"]\n",
    "haftalık_ozet[\"d_inv\"] = haftalık_ozet[\"d_inv\"].astype(int)\n",
    "\n",
    "haftalık_ozet.loc[1:,\"t_v_y\"] = haftalık_ozet.loc[1:,\"t_v_y\"] + haftalık_ozet.loc[1:,\"d_inv\"]\n",
    "haftalık_ozet.insert(4,\"d_%\",(round(haftalık_ozet[\"t_v\"] / haftalık_ozet[\"t_v_y\"],4) - 1) * 100)\n",
    "\n",
    "haftalık_ozet[\"d_b\"] = haftalık_ozet[\"d_inv\"] + (haftalık_ozet[\"d_a_c\"])\n",
    "haftalık_ozet[\"a_b\"] = haftalık_ozet[\"d_b\"].cumsum()\n",
    "\n",
    "haftalık_ozet[\"a_r_p\"] = haftalık_ozet[\"a_r_p\"].round(2)\n",
    "haftalık_ozet[\"a_ur_p\"] = haftalık_ozet[\"a_ur_p\"].round(2)\n",
    "haftalık_ozet[\"d_p\"] = haftalık_ozet[\"d_r_p\"] + haftalık_ozet[\"d_ur_p\"]\n",
    "haftalık_ozet[\"d_p_y\"] = round(haftalık_ozet[\"d_p\"] / haftalık_ozet[\"t_v\"],4) * 100\n",
    "\n",
    "# haftalık_ozet\n",
    "# haftalık_ozet.to_parquet(\"haftalık_ozet.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28-09-2023'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "now = datetime.now()\n",
    "if now.weekday() >= 5:  # 5: Saturday, 6: Sunday\n",
    "    # If today is Saturday, subtract 1 day to get Friday's data\n",
    "    # If today is Sunday, subtract 2 days to get Friday's data\n",
    "    days_to_subtract = now.weekday() - 4\n",
    "    today_str = (now - timedelta(days=days_to_subtract)).strftime(\"%d-%m-%Y\")\n",
    "else:\n",
    "    # For weekdays, if the current time is before 18:00, use yesterday's date\n",
    "    if now.hour < 18:\n",
    "        today_str = (now - timedelta(days=1)).strftime(\"%d-%m-%Y\")\n",
    "    else:\n",
    "        # If the current time is 18:00 or later, use today's date\n",
    "        today_str = now.strftime(\"%d-%m-%Y\")\n",
    "today_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplam_buyukluk = port_all.query(\"date == @today_str\").t_v.sum()\n",
    "gunluk_net = gunluk_ozet.query(\"date == @today_str\").d_p.values[0]\n",
    "gunluk_yuzde = gunluk_ozet.query(\"date == @today_str\").d_p_y.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230929'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "you are using nologin method, data you access may be limited\n"
     ]
    }
   ],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "tv = TvDatafeed()\n",
    "\n",
    "def fetch_data(ticker):\n",
    "    data = tv.get_hist(symbol=ticker, exchange='BIST', interval=Interval.in_daily, n_bars=200)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-07 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>5001.9702</td>\n",
       "      <td>5014.5698</td>\n",
       "      <td>4773.3799</td>\n",
       "      <td>4827.0400</td>\n",
       "      <td>5.669737e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-08 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>4823.3301</td>\n",
       "      <td>4859.2700</td>\n",
       "      <td>4711.4302</td>\n",
       "      <td>4855.9199</td>\n",
       "      <td>5.058030e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>4875.2202</td>\n",
       "      <td>5015.2300</td>\n",
       "      <td>4871.2798</td>\n",
       "      <td>5005.2998</td>\n",
       "      <td>4.786662e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-12 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>5057.5298</td>\n",
       "      <td>5222.5498</td>\n",
       "      <td>5057.5298</td>\n",
       "      <td>5193.2998</td>\n",
       "      <td>7.118074e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-13 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>5212.5801</td>\n",
       "      <td>5299.3301</td>\n",
       "      <td>5179.8198</td>\n",
       "      <td>5256.1899</td>\n",
       "      <td>6.766963e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-22 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8035.0498</td>\n",
       "      <td>8094.0298</td>\n",
       "      <td>7981.2300</td>\n",
       "      <td>8039.1802</td>\n",
       "      <td>4.187311e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-25 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8105.3599</td>\n",
       "      <td>8311.1602</td>\n",
       "      <td>8096.9502</td>\n",
       "      <td>8304.8301</td>\n",
       "      <td>4.864111e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-26 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8368.5098</td>\n",
       "      <td>8389.6797</td>\n",
       "      <td>8240.8301</td>\n",
       "      <td>8242.2598</td>\n",
       "      <td>5.966519e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-27 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8275.1396</td>\n",
       "      <td>8298.6504</td>\n",
       "      <td>8170.8901</td>\n",
       "      <td>8213.7598</td>\n",
       "      <td>4.426915e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-28 09:00:00</th>\n",
       "      <td>BIST:XU100</td>\n",
       "      <td>8235.7900</td>\n",
       "      <td>8288.4805</td>\n",
       "      <td>8187.9600</td>\n",
       "      <td>8218.7402</td>\n",
       "      <td>4.110880e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         symbol       open       high        low      close   \n",
       "datetime                                                                      \n",
       "2022-12-07 09:00:00  BIST:XU100  5001.9702  5014.5698  4773.3799  4827.0400  \\\n",
       "2022-12-08 09:00:00  BIST:XU100  4823.3301  4859.2700  4711.4302  4855.9199   \n",
       "2022-12-09 09:00:00  BIST:XU100  4875.2202  5015.2300  4871.2798  5005.2998   \n",
       "2022-12-12 09:00:00  BIST:XU100  5057.5298  5222.5498  5057.5298  5193.2998   \n",
       "2022-12-13 09:00:00  BIST:XU100  5212.5801  5299.3301  5179.8198  5256.1899   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "2023-09-22 09:00:00  BIST:XU100  8035.0498  8094.0298  7981.2300  8039.1802   \n",
       "2023-09-25 09:00:00  BIST:XU100  8105.3599  8311.1602  8096.9502  8304.8301   \n",
       "2023-09-26 09:00:00  BIST:XU100  8368.5098  8389.6797  8240.8301  8242.2598   \n",
       "2023-09-27 09:00:00  BIST:XU100  8275.1396  8298.6504  8170.8901  8213.7598   \n",
       "2023-09-28 09:00:00  BIST:XU100  8235.7900  8288.4805  8187.9600  8218.7402   \n",
       "\n",
       "                           volume  \n",
       "datetime                           \n",
       "2022-12-07 09:00:00  5.669737e+09  \n",
       "2022-12-08 09:00:00  5.058030e+09  \n",
       "2022-12-09 09:00:00  4.786662e+09  \n",
       "2022-12-12 09:00:00  7.118074e+09  \n",
       "2022-12-13 09:00:00  6.766963e+09  \n",
       "...                           ...  \n",
       "2023-09-22 09:00:00  4.187311e+09  \n",
       "2023-09-25 09:00:00  4.864111e+09  \n",
       "2023-09-26 09:00:00  5.966519e+09  \n",
       "2023-09-27 09:00:00  4.426915e+09  \n",
       "2023-09-28 09:00:00  4.110880e+09  \n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data(\"XU100\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
